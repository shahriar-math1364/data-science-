# -*- coding: utf-8 -*-
"""women_celebrity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aVjV9711RMVIrAivZhTLMbrjT4gXlbNA
"""

!pip install opencv-python

# Commented out IPython magic to ensure Python compatibility.
import numpy as np

import cv2
import matplotlib
from matplotlib import pyplot as plt
# %matplotlib inline

path='C:\\Dmitry\\machine learning\\Women celebrity\\rihanna images - Google Search\\_url=https_3A_2F_2Fcalifornia-times-brightspot.s3.amazonaws.jpg'

image = cv2.imread(path)

plt.imshow(image)

path="C:\\Python Project\\project 1\\images\\katy perry images - Google Search6.png"

image = cv2.imread(path)

plt.imshow(image)

gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
gray.shape

plt.imshow(gray, cmap='gray')

face_cas = cv2.CascadeClassifier('C:\\Users\\mirzadsr\\AppData\\Roaming\\Python\\Python311\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml')
eye_cas= cv2.CascadeClassifier("C:\\Users\\mirzadsr\\AppData\\Roaming\\Python\\Python311\\site-packages\\cv2\\data\\\\haarcascade_eye.xml")

faces = face_cas.detectMultiScale(gray, 1.3, 2)
(x,y,w,h) = faces[0]
x,y,w,h
face_img = cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)
plt.imshow(face_img)

cv2.destroyAllWindows()
for (x,y,w,h) in faces:
    face_img = cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)
    roi_gray = gray[y:y+h, x:x+w]
    roi_color = face_img[y:y+h, x:x+w]
    eyes = eye_cas.detectMultiScale(roi_gray)

    for (ex,ey,ew,eh) in eyes:
        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)


plt.figure()
plt.imshow(face_img, cmap='gray')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
plt.imshow(roi_color, cmap='gray')

faces

import numpy as np
import pywt
import cv2

def w2d(img, mode='haar', level=1):
    imArray = img
    #Datatype conversions
    #convert to grayscale
    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )
    #convert to float
    imArray =  np.float32(imArray)
    imArray /= 255;
    # compute coefficients
    coeffs=pywt.wavedec2(imArray, mode, level=level)

    #Process Coefficients
    coeffs_H=list(coeffs)
    coeffs_H[0] *= 0;

    # reconstruction
    imArray_H=pywt.waverec2(coeffs_H, mode);
    imArray_H *= 255;
    imArray_H =  np.uint8(imArray_H)

    return imArray_H

im_har = w2d(cropped_img,'db1',5)
plt.imshow(im_har, cmap='gray')

"""# Preprocessing

We use this python function which takes the picture and return cropped image if more than 2 eyes are detected:
"""

def get_cropped_image_if_2_eyes(image_path):
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cas.detectMultiScale(gray, 1.3, 5)
    for (x,y,w,h) in faces:
        roi_gray = gray[y:y+h, x:x+w]
        roi_color = img[y:y+h, x:x+w]
        eyes = eye_cas.detectMultiScale(roi_gray)
        if len(eyes) >= 2:
            return roi_color

"""For example consider the follwing image:"""

path="C:\\Python Project\Women celebrity\\katy perry images - Google Search\\45fc2f925862-katy-perry-idol.jpg"
image=cv2.imread(path)
plt.imshow(image)

"""We use our function to crop the face in the above picture and show the cropped picture using plt.imshow"""

cropped_image = get_cropped_image_if_2_eyes(path)
plt.imshow(cropped_image)

"""However, in the following picture the eyes are not clear, so our function will return None, which means that we have to ignore this image:"""

path=path="C:\\Dmitry\\machine learning\\Women celebrity\\rihanna images - Google Search\\230212-super-bowl-rihanna-jm-2130-fa1ea3.jpg"
image=cv2.imread(path)
plt.imshow(image)

cropped_image = get_cropped_image_if_2_eyes(path)
cropped_image

print(cropped_image)

"""Now we would like to use our function and go through all the pictures of Rihana and Kathy Perry and get the cropped image of all images and save them in a new folder."""

path_to_data = "C:\\Dmitry\\machine learning\\Women celebrity"
path_to_cr_data = "C:\\Dmitry\\machine learning\\Women celebrity\\cropped"

import os
img_dirs = []
for entry in os.scandir(path_to_data):
    if entry.is_dir():
        img_dirs.append(entry.path)

img_dirs

import shutil
if os.path.exists(path_to_cr_data):
     shutil.rmtree(path_to_cr_data)
os.mkdir(path_to_cr_data)

cropped_image_dirs = []
celebrity_file_names_dict = {}
for img_dir in img_dirs:
    count = 1
    celebrity_name = img_dir.split('\\')[-1]
    celebrity_file_names_dict[celebrity_name] = []
    for entry in os.scandir(img_dir):
        roi_color = get_cropped_image_if_2_eyes(entry.path)
        if roi_color is not None:
            cropped_folder = path_to_cr_data + celebrity_name
            if not os.path.exists(cropped_folder):
                os.makedirs(cropped_folder)
                cropped_image_dirs.append(cropped_folder)
                print("Generating cropped images in folder: ",cropped_folder)
            cropped_file_name = celebrity_name + str(count) + ".png"
            cropped_file_path = cropped_folder + "\\" + cropped_file_name
            cv2.imwrite(cropped_file_path, roi_color)
            celebrity_file_names_dict[celebrity_name].append(cropped_file_path)
            count += 1

cropped_image_dirs=["C:\\Users\\mirzadsr\\Python Projects\\cropped\\katy perry",
 'C:\\Users\\mirzadsr\\Python Projects\\cropped\\rihanna', 'C:\\Users\\mirzadsr\\Python Projects\\cropped\\lady gaga','C:\\Users\\mirzadsr\\Python Projects\\cropped\\beyonce']

import os
celebrity_file_names_dict = {}
for img_dir in cropped_image_dirs:
    celebrity_name = img_dir.split('\\')[-1]
    file_list = []
    for entry in os.scandir(img_dir):
        file_list.append(entry.path)
    celebrity_file_names_dict[celebrity_name] = file_list
celebrity_file_names_dict

class_dict = {}
count = 0
for celebrity_name in celebrity_file_names_dict.keys():
    class_dict[celebrity_name] = count
    count = count + 1
class_dict

"""# Training the model"""

X, y = [], []
for celebrity_name, training_files in celebrity_file_names_dict.items():
    for training_image in training_files:
        img = cv2.imread(training_image)
        scalled_raw_img = cv2.resize(img, (32, 32))
        img_har = w2d(img,'db1',5)
        scalled_img_har = cv2.resize(img_har, (32, 32))
        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))
        X.append(combined_img)
        y.append(class_dict[celebrity_name])

X

len(X[0])

X = np.array(X).reshape(len(X),4096).astype(float)
X.shape

from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
model=SVC(kernel='rbf',C=10)
pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10))])
pipe.fit(X_train, y_train)
pipe.score(X_test, y_test)

print(classification_report(y_test, pipe.predict(X_test)))

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier







classifiers = {
    "Random Forest": (RandomForestClassifier(),
                       {'n_estimators': [10, 50, 100],
                        'max_depth': [None, 10, 20, 30]}),

    "SVM": (SVC(),
            {'C': [0.1, 1, 10, 1000],
             'kernel': ['linear', 'rbf']}),

    "Logistic Regression": (LogisticRegression(),
                            {'C': [0.1, 1, 10],
                             'penalty': ['l1', 'l2']}),

    "K-Nearest Neighbors": (KNeighborsClassifier(),
                            {'n_neighbors': [3, 5, 7],
                             'weights': ['uniform', 'distance']}),

    "Decision Tree": (DecisionTreeClassifier(),
                      {'max_depth': [None, 10, 20, 30],
                       'min_samples_split': [2, 5, 10]})

}

# Create an empty DataFrame to store results
import pandas as pd
results_df = pd.DataFrame(columns=['Model', 'Best Parameters', 'Best Score'])

# Loop through the classifiers and perform GridSearchCV
scaler = StandardScaler()

# Scale the training and test data
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Loop through the classifiers and perform GridSearchCV
for name, (model, param_grid) in classifiers.items():
    grid_search = GridSearchCV(model, param_grid, cv=5)
    grid_search.fit(X_train_scaled, y_train)
    y_pred = grid_search.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)
    print(classification_report(y_test, y_pred))

    # Store results in the DataFrame
    results_df = results_df.append({'Model': name, 'Best Parameters': grid_search.best_params_, 'Best Score': accuracy}, ignore_index=True)
    print(results_df)

# Sort the DataFrame by the best score in descending order
results_df = results_df.sort_values(by='Best Score', ascending=False)

# Display the results
print(results_df)

results_df['Best Parameters'][1]

model=Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'linear', C = 0.1, probability=True))])

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(classification_report(y_test, y_pred))

import pickle
with open('model_pickle','wb') as f:
    pickle.dump(model,f)

